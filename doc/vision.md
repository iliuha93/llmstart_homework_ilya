# Техническое видение проекта

## Содержание
1. [Технологии](#технологии)
2. [Принцип разработки](#принцип-разработки)
3. [Структура проекта](#структура-проекта)
4. [Архитектура проекта](#архитектура-проекта)
5. [Модель данных](#модель-данных)
6. [Работа с LLM](#работа-с-llm)
7. [Мониторинг LLM](#мониторинг-llm)
8. [Сценарии работы](#сценарии-работы)
9. [Деплой](#деплой)
10. [Подход к конфигурированию](#подход-к-конфигурированию)
11. [Подход к логгированию](#подход-к-логгированию)

---

## Технологии

**Основной стек:**
- **Python 3.11+** - основной язык разработки
- **aiogram** - асинхронная библиотека для работы с Telegram Bot API
- **OpenAI Python Client** - для работы с LLM через OpenRouter API

**Управление проектом:**
- **uv** - управление зависимостями и Python окружением
- **make** - автоматизация сборки, запуска и тестирования
- **Docker** - контейнеризация для деплоя

**Разработка и тестирование:**
- **pytest** - фреймворк для тестирования

**Хранение данных:**
- **dict/list** - простые структуры Python для хранения истории диалогов в памяти
- **Нет базы данных** - вся информация о компании и услугах заложена в системный промпт

---

## Принцип разработки

**Основные принципы:**
- **KISS (Keep It Simple, Stupid)** - максимальная простота во всем
- **MVP подход** - минимально жизнеспособный продукт для проверки идеи
- **Итеративная разработка** - небольшие инкременты, быстрая обратная связь
- **Fail Fast** - быстрое выявление проблем и исправление
- **Single Responsibility** - каждый модуль отвечает за одну задачу

**Подход к коду:**
- **PEP8** - стандарт стиля кода Python
- **Минимум зависимостей** - только необходимые библиотеки
- **Читаемость превыше всего** - код должен быть понятен без комментариев

---

## Структура проекта

```
llmstart_homework_ilya/
├── main.py              # Точка входа в приложение
├── config.py            # Конфигурация приложения
├── bot/                 # Модули для работы с Telegram API
│   ├── __init__.py
│   └── handlers.py      # Обработчики сообщений
├── llm/                 # Модули для работы с LLM
│   ├── __init__.py
│   └── client.py        # Клиент для работы с OpenRouter/OpenAI
├── tests/               # Тесты
│   └── test_bot.py      # Тесты для бота
├── doc/                 # Документация
│   ├── product_idea.md
│   └── vision.md
├── Dockerfile           # Файл для сборки Docker-контейнера
├── Makefile            # Файл для автоматизации задач
├── pyproject.toml       # Конфигурация проекта и зависимости для uv
└── .env      # Пример переменных окружения
```

**Принципы организации:**
- **Модульность** - разделение по функциональности (bot, llm)
- **Простота** - минимум вложенности, понятные имена
- **Стандартность** - следование Python conventions

---

## Архитектура проекта

Архитектура проекта следует принципам простоты и функциональности:

1. **Компонентный подход** - четкое разделение ответственности между модулями
2. **Функциональное программирование** - использование функций вместо классов
3. **Простая схема взаимодействия**: Telegram -> Бот -> LLM -> Бот -> Telegram

```
┌─────────────┐    ┌──────────────┐    ┌─────────────┐
│  Telegram   │◄──►│ Бот (aiogram)│◄──►│ LLM Client  │
│ (клиент)    │    │ (обработчики)│    │(OpenRouter) │
└─────────────┘    └──────────────┘    └─────────────┘
       ▲                   ▲                   ▲
       │                   │                   │
   Сообщение           Запрос              Ответ
       │                   │                   │
       ▼                   ▼                   ▼
     Ответ               Ответ               Ответ
```

**Компоненты:**
- **main.py** - точка входа, инициализация бота
- **bot/handlers.py** - обработка сообщений от пользователей
- **llm/client.py** - взаимодействие с OpenRouter API
- **config.py** - конфигурация и системные промпты

---

## Модель данных

**Структура сообщения:**
```python
message = {
    "role": "system" | "user" | "assistant",
    "content": "текст сообщения"
}
```

**Структура диалога:**
```python
dialogs = {
    "chat_id": {
        "messages": [
            {"role": "system", "content": "системный промпт"},
            {"role": "user", "content": "вопрос пользователя"},
            {"role": "assistant", "content": "ответ бота"},
            {"role": "user", "content": "следующий вопрос"},
            {"role": "assistant", "content": "следующий ответ"}
        ]
    }
}
```

**Принципы:**
- **Простые типы данных** - dict, list, str
- **Хранение в памяти** - никакой персистентности
- **Стандартный формат** - совместимость с OpenAI API
- **Минимум метаданных** - только необходимое

---

## Работа с LLM

Для взаимодействия с языковой моделью используем следующий подход:

1. **API**: Используем OpenRouter API через реализацию OpenAI client
2. **Системный промпт**: Включаем информацию о компании и услугах в системный промпт
3. **Контекст**: Отправляем историю диалога для сохранения контекста общения
4. **Обработка ответов**: Простая обработка ответов от LLM без дополнительной постобработки

```python
# Пример функции для работы с LLM
async def get_llm_response(dialog_history):
    response = await openai_client.chat.completions.create(
        model="openrouter/model_name",  # Конкретная модель через OpenRouter
        messages=dialog_history,
        temperature=0.7,
        max_tokens=500
    )
    return response.choices[0].message.content
```

---

## Мониторинг LLM

**Логирование запросов и ответов LLM:**
- **Сохраняем взаимодействия с LLM** для анализа и отладки
- **Полное логирование** - запросы, ответы,
- **Структурированные логи** - для удобного анализа

---

## Сценарии работы

**1. Приветствие и знакомство с клиентом:**
- Бот представляется как консультант компании

**2. Ответы на вопросы о компании и услугах:**
- Бот отвечает на вопросы о компании на основе системного промпта
- Бот может задать уточняющие вопросы для лучшего понимания потребностей

---

## Деплой

**Подход:**
- **Docker контейнер** - простая контейнеризация приложения
- **Одиночный контейнер** - весь бот в одном образе
- **Переменные окружения** - конфигурация через .env файл

---

## Подход к конфигурированию

Для конфигурации приложения используем простой и безопасный подход:

1. **Файл .env** - хранение всех конфигурационных параметров и переменных окружения:
   - API ключи и токены
   - Параметры LLM
   - Системный промпт
   - Другие настройки бота

---

## Подход к логгированию

Для логирования используем стандартный и проверенный подход:

1. **Стандартный модуль logging** - использование встроенного в Python модуля для логирования
2. **Логирование основных событий**:
   - Запуск и остановка бота
   - Ошибки и исключения
   - Запросы и ответы LLM
3. **Уровни логирования**:
   - INFO - стандартные информационные сообщения
   - ERROR - ошибки и исключения
   - DEBUG - подробная отладочная информация

